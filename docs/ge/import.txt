Hello team.

I want to share with you one idea of how we can implement the derivation model importing process.

* Main idea

I propose to introduce a staging area on the database level.
We can make all required operations in this area in parallel and bulk mode.
After that, when we have a valid model at the staging area, we can copy them into actual tables in a single transaction.

If we get a bottleneck in the final stage, we can create two sets of the derivation model (blue and green)
and we can switch it at runtime. But it is another story.

* Detailed description.

The importing process will contain the following stages:

* Parsing
* Translation
* Merging
* Validation
* Applying

These stages will be executed sequentially.

Parsing

In this phase we will take the following actions:
* We will parse JSON files and we will create Java objects.
* We will store Java objects in staging tables in a database.

This phase will have the following key aspects.

* We will use several files to store the derivation model.
* Each file will contain a lot of derivation models.
* Each file can refer to the item from another file.
* We will parse those files in parallel mode.
* We will store data from those files in staging tables.
* We do not worry about model consistency in this phase.
* We will store data in parallel and we will not worry about data dependencies between data
* The tables in the staging area will not have foreign key constraints.
* We will make a minimal validation at this stage. We will check the data type and length of the fields.
* We will not make a complex transformation in this phase.
* We will store information as plain text.

Translation

In this phase, we will translate text values into a reference to other data.

We will make those translations in parallel mode.
We can split translation into chunks.
We will make those translations in bulk mode.
Most translations will be made as a simple database query.
We will use a minimal amount of memory, CPU, and IO on the application server.
We will not transmit a lot of data between an application server and a database in this phase.

Merging

In this phase, we will merge the current derivation model into the staging area.

We will make this in bulk mode
We will make this in parallel mode
We will use a minimal amount of memory, CPU, and IO on the application server.
We will make this operation via simple queries. (insert/update from select )

Validation

In this phase, we will validate data consistency across the whole model.

We will make this in bulk mode
We will make this in parallel mode
We will use a minimal amount of memory, CPU, and IO on the application server.
We will use simple queries to make validations

Applying

In this phase, we will copy the valid derivation model from the staging table to the actual table.

We will copy data sequentially according to data dependencies.
We will execute this in a single transaction.
We will execute this in a single thread.
We will use a minimal amount of memory, CPU, and IO on the application server.
We will make this operation via simple queries. (insert/update from select )